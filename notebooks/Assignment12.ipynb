{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\rawan\\OneDrive\\Desktop\\Media Mining\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set this to your workspace root\n",
    "# os.chdir(r\"Mining media\")\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "def split_jsonl_file(input_path, train_path, test_path, test_ratio=0.2):\n",
    "    with open(input_path, 'r', encoding='utf-8') as infile, \\\n",
    "         open(train_path, 'w', encoding='utf-8') as train_file, \\\n",
    "         open(test_path, 'w', encoding='utf-8') as test_file:\n",
    "        \n",
    "        for line in infile:\n",
    "            if random.random() < test_ratio:\n",
    "                test_file.write(line)\n",
    "            else:\n",
    "                train_file.write(line)\n",
    "\n",
    "# Example\n",
    "split_jsonl_file(\"data/game2_processed/playerLogs_game2_playerbasedlines.jsonl\", \"data/game2_processed/train.jsonl\", \"data/game2_processed/test.jsonl\", test_ratio=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features and prepare model dataset\n",
    "\n",
    "We only extracted 10000 lines for training and 5000 lines for testing (because my laptop couldnt handle more)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def parse_datetime(dt_str):\n",
    "    \"\"\"\n",
    "    Convert ISO format datetime string to datetime object.\n",
    "    \n",
    "    Args:\n",
    "        dt_str (str): Datetime string in ISO format with 'Z' timezone marker\n",
    "        \n",
    "    Returns:\n",
    "        datetime: Parsed datetime object with UTC timezone\n",
    "    \"\"\"\n",
    "    return datetime.fromisoformat(dt_str.replace(\"Z\", \"+00:00\"))\n",
    "\n",
    "def extract_features(events, uid):\n",
    "    \"\"\"\n",
    "    Extract features from a user's event history for churn prediction.\n",
    "    \n",
    "    The function splits the data into two periods:\n",
    "    1. Observation period: First 5 days of user activity\n",
    "    2. Prediction period: Following 10 days\n",
    "    \n",
    "    Args:\n",
    "        events (list): List of event dictionaries containing user activity data\n",
    "        uid (str): User identifier\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing extracted features, or None if no valid events\n",
    "        \n",
    "    Features extracted:\n",
    "        - play_count: Total number of events in observation period\n",
    "        - active_days: Number of unique days with activity\n",
    "        - total_reward: Sum of all rewards earned\n",
    "        - mean_reward: Average reward per event\n",
    "        - reward_std: Standard deviation of rewards\n",
    "        - days_since_last_play: Days between last activity and observation end\n",
    "        - avg_session_gap: Average hours between consecutive events\n",
    "        - last_7_days_activity: Binary indicator of activity in last week\n",
    "        - churn: Binary indicator of user churning in prediction period\n",
    "    \"\"\"\n",
    "    if not events:\n",
    "        return None\n",
    "\n",
    "    # Sort events chronologically and define time windows\n",
    "    events = sorted(events, key=lambda x: parse_datetime(x['date']))\n",
    "    start_time = parse_datetime(events[0]['date'])\n",
    "    obs_end = start_time + timedelta(days=5)    # End of observation period\n",
    "    pred_end = obs_end + timedelta(days=10)     # End of prediction period\n",
    "\n",
    "    # Split events into observation and prediction periods\n",
    "    obs_events = [e for e in events if parse_datetime(e['date']) < obs_end]\n",
    "    pred_events = [e for e in events if obs_end <= parse_datetime(e['date']) < pred_end]\n",
    "\n",
    "    if not obs_events:\n",
    "        return None\n",
    "\n",
    "    # Extract basic event information\n",
    "    times = [parse_datetime(e['date']) for e in obs_events]\n",
    "    actions = [e.get('event', '') for e in obs_events]\n",
    "    rewards = [e.get('reward', 0) for e in obs_events]\n",
    "\n",
    "    # Calculate activity patterns\n",
    "    active_days = {t.date() for t in times}  # Set of unique active days\n",
    "    # Calculate time gaps between consecutive events (in hours)\n",
    "    gaps = [(times[i+1] - times[i]).total_seconds() / 3600 for i in range(len(times)-1)]\n",
    "\n",
    "    # Construct feature dictionary\n",
    "    return {\n",
    "        'uid': uid,\n",
    "        'play_count': len(obs_events),          # Total number of events\n",
    "        'active_days': len(active_days),        # Number of unique active days\n",
    "        'mean_score': np.mean(rewards),        # Average reward per event\n",
    "        'score_std': np.std(rewards), \n",
    "        'best_score': max(rewards),         # Reward variability\n",
    "        'days_since_last_play': (obs_end - max(times)).days,  # Recency of last activity\n",
    "        'avg_session_gap': np.mean(gaps) if gaps else 0,      # Average time between events\n",
    "        'last_7_days_activity': int(any((obs_end - t).days <= 7 for t in times)),  # Recent activity indicator\n",
    "        'churn': (len(pred_events) == 0)     # Churn label (1 if no activity in prediction period)\n",
    "    }\n",
    "\n",
    "## We only extracted 10000 lines for training\n",
    "def stream_features_to_csv_train(jsonl_path, output_csv):\n",
    "    \"\"\"\n",
    "    Process a JSONL file of user events and write extracted features to CSV.\n",
    "    \n",
    "    This function processes the input file line by line to handle large files\n",
    "    efficiently. For each user, it flattens their event records and extracts\n",
    "    features for churn prediction.\n",
    "    \n",
    "    Args:\n",
    "        jsonl_path (str): Path to input JSONL file containing user events\n",
    "        output_csv (str): Path where the output CSV file will be written\n",
    "        \n",
    "    Side effects:\n",
    "        - Creates or overwrites the output CSV file\n",
    "        - Prints progress messages every 10,000 lines\n",
    "        - Prints error messages for skipped lines\n",
    "    \"\"\"\n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as infile, \\\n",
    "         open(output_csv, 'w', encoding='utf-8', newline='') as outfile:\n",
    "\n",
    "        writer = None\n",
    "        for i, line in enumerate(infile):\n",
    "            try:\n",
    "                # Parse each line as a user record\n",
    "                row = json.loads(line)\n",
    "                uid = row.get('uid')\n",
    "                records = row.get('records', [])\n",
    "                \n",
    "                # Flatten and normalize event records\n",
    "                flat_events = []\n",
    "                for event in records:\n",
    "                    props = event.get('properties') or {}\n",
    "                    flat_events.append({\n",
    "                        'date': event.get('date'),\n",
    "                        'event': event.get('event', ''),\n",
    "                        # Extract numeric properties with safe fallbacks\n",
    "                        'reward': props.get('reward', 0) if isinstance(props, dict) else 0,\n",
    "                        'package': props.get('package', 0) if isinstance(props, dict) else 0\n",
    "                    })\n",
    "\n",
    "                # Extract features and write to CSV\n",
    "                features = extract_features(flat_events, uid)\n",
    "                if features:\n",
    "                    # Initialize CSV writer with headers on first valid record\n",
    "                    if writer is None:\n",
    "                        writer = csv.DictWriter(outfile, fieldnames=list(features.keys()))\n",
    "                        writer.writeheader()\n",
    "                    writer.writerow(features)\n",
    "\n",
    "                # Print progress update every 10,000 records\n",
    "                if (i + 1) % 10000 == 0:\n",
    "                    print(f\"Processed {i+1} lines...\")\n",
    "\n",
    "                if (i + 1) % 20000 == 0:\n",
    "                    break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping line {i} due to error: {e}\")\n",
    "                continue\n",
    "\n",
    "    print(f\"âœ… Finished writing features to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##We only extracted 5000 lines for testing\n",
    "def stream_features_to_csv_test(jsonl_path, output_csv):\n",
    "    \"\"\"\n",
    "    Process a JSONL file of user events and write extracted features to CSV.\n",
    "    \n",
    "    This function processes the input file line by line to handle large files\n",
    "    efficiently. For each user, it flattens their event records and extracts\n",
    "    features for churn prediction.\n",
    "    \n",
    "    Args:\n",
    "        jsonl_path (str): Path to input JSONL file containing user events\n",
    "        output_csv (str): Path where the output CSV file will be written\n",
    "        \n",
    "    Side effects:\n",
    "        - Creates or overwrites the output CSV file\n",
    "        - Prints progress messages every 10,000 lines\n",
    "        - Prints error messages for skipped lines\n",
    "    \"\"\"\n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as infile, \\\n",
    "         open(output_csv, 'w', encoding='utf-8', newline='') as outfile:\n",
    "\n",
    "        writer = None\n",
    "        for i, line in enumerate(infile):\n",
    "            try:\n",
    "                # Parse each line as a user record\n",
    "                row = json.loads(line)\n",
    "                uid = row.get('uid')\n",
    "                records = row.get('records', [])\n",
    "                \n",
    "                # Flatten and normalize event records\n",
    "                flat_events = []\n",
    "                for event in records:\n",
    "                    props = event.get('properties') or {}\n",
    "                    flat_events.append({\n",
    "                        'date': event.get('date'),\n",
    "                        'event': event.get('event', ''),\n",
    "                        # Extract numeric properties with safe fallbacks\n",
    "                        'reward': props.get('reward', 0) if isinstance(props, dict) else 0,\n",
    "                        'package': props.get('package', 0) if isinstance(props, dict) else 0\n",
    "                    })\n",
    "\n",
    "                # Extract features and write to CSV\n",
    "                features = extract_features(flat_events, uid)\n",
    "                if features:\n",
    "                    # Initialize CSV writer with headers on first valid record\n",
    "                    if writer is None:\n",
    "                        writer = csv.DictWriter(outfile, fieldnames=list(features.keys()))\n",
    "                        writer.writeheader()\n",
    "                    writer.writerow(features)\n",
    "\n",
    "                # Print progress update every 10,000 records\n",
    "                if (i + 1) % 10000 == 0:\n",
    "                    print(f\"Processed {i+1} lines...\")\n",
    "\n",
    "                if (i + 1) % 5000 == 0:\n",
    "                    break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping line {i} due to error: {e}\")\n",
    "                continue\n",
    "\n",
    "    print(f\"âœ… Finished writing features to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10000 lines...\n",
      "Processed 20000 lines...\n",
      "âœ… Finished writing features to data/game2_processed/train_features.csv\n"
     ]
    }
   ],
   "source": [
    "stream_features_to_csv_train(\"data/game2_processed/train.jsonl\", \"data/game2_processed/train_features.csv\")\n",
    "stream_features_to_csv_test(\"data/game2_processed/test.jsonl\", \"data/game2_processed/test_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "ds1 = pd.read_csv(\"data/game2_processed/train_features.csv\")\n",
    "ds2 = pd.read_csv(\"data/game2_processed/test_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree...\n",
      "Training Random Forest...\n",
      "Training Logistic Regression...\n",
      "\n",
      "Decision Tree Feature Importance:\n",
      "days_since_last_play    0.671280\n",
      "play_count              0.228508\n",
      "active_days             0.034674\n",
      "best_score              0.033863\n",
      "avg_session_gap         0.022337\n",
      "score_std               0.005749\n",
      "mean_score              0.003589\n",
      "last_7_days_activity    0.000000\n",
      "dtype: float64\n",
      "\n",
      "Random Forest Feature Importance:\n",
      "days_since_last_play    0.305510\n",
      "active_days             0.273786\n",
      "play_count              0.181291\n",
      "avg_session_gap         0.098779\n",
      "best_score              0.060983\n",
      "score_std               0.044240\n",
      "mean_score              0.035409\n",
      "last_7_days_activity    0.000000\n",
      "dtype: float64\n",
      "\n",
      "Saved test predictions: ../data/game2_processed/ds2_with_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def prepare_model_data(ds1, ds2):\n",
    "    \"\"\"Prepare features and labels for modeling\"\"\"\n",
    "    # Features (exclude device ID and churn label)\n",
    "    feature_cols = [col for col in ds1.columns if col not in ['uid', 'churn']]\n",
    "    \n",
    "    # DS1 (Train)\n",
    "    X_train = ds1[feature_cols]\n",
    "    y_train = ds1['churn']\n",
    "    \n",
    "    # DS2 (Test) \n",
    "    X_test = ds2[feature_cols]\n",
    "    \n",
    "    # Impute missing values (using train stats)\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_test = imputer.transform(X_test)\n",
    "    \n",
    "    # Scale features (using train stats)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, feature_cols\n",
    "\n",
    "def train_models(X_train, y_train):\n",
    "    \"\"\"Train multiple classifiers\"\"\"\n",
    "    models = {\n",
    "        'Decision Tree': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42)\n",
    "    }\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    return models\n",
    "\n",
    "def evaluate_models(models, X_test, ds2, feature_cols):\n",
    "    \"\"\"Evaluate models on test data\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        # Get predicted probabilities\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        ds2[f'{name}_churn_prob'] = y_proba\n",
    "        \n",
    "        # Feature importance (for tree models)\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importance = pd.Series(model.feature_importances_, index=feature_cols)\n",
    "            print(f\"\\n{name} Feature Importance:\")\n",
    "            print(importance.sort_values(ascending=False).head(10))\n",
    "        \n",
    "        results[name] = model\n",
    "    \n",
    "    # Save test results with predictions\n",
    "    ds2.to_csv(\"data/game2_processed/ds2_with_predictions.csv\", index=False)\n",
    "    print(\"\\nSaved test predictions: ../data/game2_processed/ds2_with_predictions.csv\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Prepare data\n",
    "X_train, X_test, y_train, feature_cols = prepare_model_data(ds1, ds2)\n",
    "\n",
    "# Train models\n",
    "models = train_models(X_train, y_train)\n",
    "\n",
    "# Evaluate on DS2\n",
    "model_results = evaluate_models(models, X_test, ds2, feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DS1 (training) as JSONL: ../data/game2_processed/ds1_train.jsonl\n",
      "Saved DS2 (test) as JSONL: ../data/game2_processed/ds2_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Save datasets in JSONL format\n",
    "import jsonlines\n",
    "\n",
    "def save_to_jsonl(df, path):\n",
    "    with jsonlines.open(path, 'w') as writer:\n",
    "        writer.write_all(df.to_dict('records'))\n",
    "\n",
    "# Save DS1 (training data)\n",
    "save_to_jsonl(ds1, \"data/game2_processed/ds1_train.jsonl\")\n",
    "print(\"Saved DS1 (training) as JSONL: ../data/game2_processed/ds1_train.jsonl\")\n",
    "\n",
    "# Save DS2 (test data) - without churn labels if they don't exist\n",
    "if 'churned' in ds2.columns:\n",
    "    save_to_jsonl(ds2.drop(columns=['churned']), \"data/game2_processed/ds2_test.jsonl\")\n",
    "else:\n",
    "    save_to_jsonl(ds2, \"data/game2_processed/ds2_test.jsonl\")\n",
    "print(\"Saved DS2 (test) as JSONL: ../data/game2_processed/ds2_test.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load GPT-2 model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rawan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\rawan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\rawan\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'gpt2' and tokenizer loaded successfully with pad token set.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_id = \"gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "\n",
    "print(f\"Model '{model_id}' and tokenizer loaded successfully with pad token set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate prompts for LLM churn prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5000 prompts.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "prompts = []\n",
    "\n",
    "for index, user_data in ds2.iterrows():\n",
    "    user_id = user_data['uid']\n",
    "    play_count = user_data.get('play_count', 'N/A')\n",
    "    active_days = user_data.get('active_days', 'N/A')\n",
    "    days_since_last_play = user_data.get('days_since_last_play', 'N/A')\n",
    "    mean_score = user_data.get('mean_score', 'N/A')\n",
    "    best_score = user_data.get('best_score', 'N/A')\n",
    "    avg_session_gap = user_data.get('avg_session_gap', 'N/A')\n",
    "\n",
    "    prompt = (\n",
    "        f\"User ID: {user_id}\\n\"\n",
    "        f\"Play Count: {play_count}\\n\"\n",
    "        f\"Active Days: {active_days}\\n\"\n",
    "        f\"Days Since Last Play: {days_since_last_play}\\n\"\n",
    "        f\"Average Score: {mean_score:.2f}\\n\"\n",
    "        f\"Best Score: {best_score}\\n\"\n",
    "        f\"Session Consistency: {avg_session_gap:.2f} hours between games\\n\\n\"\n",
    "        \"Based on this user's gaming patterns, classify if they will churn (stop playing) in the next period.\\n\"\n",
    "        \"Respond with EXACTLY one word - either 'Churn' or 'NotChurn'.\"\n",
    "    )\n",
    "    prompts.append(prompt)\n",
    "\n",
    "print(f\"Generated {len(prompts)} prompts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate LLM churn predictions for a subset of users \n",
    "\n",
    "Note: for testing we only extracted 500 prompts\n",
    "\n",
    "to change this please alter this line \"for i, prompt in enumerate(prompts[:100]):\"\n",
    "\n",
    "with \"for i, prompt in enumerate(prompts):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for 5000 users...\n",
      "Processed 50 lines...\n",
      "Processed 100 lines...\n",
      "Processed 150 lines...\n",
      "Processed 200 lines...\n",
      "Processed 250 lines...\n",
      "Processed 300 lines...\n",
      "Processed 350 lines...\n",
      "Processed 400 lines...\n",
      "Processed 450 lines...\n",
      "Processed 500 lines...\n",
      "\n",
      "Prediction generation complete.\n",
      "Generated predictions for 500 users.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# First, add the analyze_prediction function at the top of your notebook or before the prediction loop\n",
    "def analyze_prediction(generated_text, user_data):\n",
    "    generated_text_lower = generated_text.lower()\n",
    "    \n",
    "    # Direct response check\n",
    "    if generated_text_lower.strip() in [\"churn\", \"notchurn\"]:\n",
    "        return \"Churn\" if generated_text_lower.strip() == \"churn\" else \"Not Churn\"\n",
    "    \n",
    "    # Confidence-based analysis\n",
    "    churn_indicators = [\"churn\", \"stop\", \"leave\", \"quit\", \"abandon\"]\n",
    "    retention_indicators = [\"stay\", \"continue\", \"engage\", \"return\", \"active\", \"not churn\", \"notchurn\"]\n",
    "    \n",
    "    churn_score = sum(1 for word in churn_indicators if word in generated_text_lower)\n",
    "    retention_score = sum(1 for word in retention_indicators if word in generated_text_lower)\n",
    "    \n",
    "    # Add behavioral weights\n",
    "    if user_data['days_since_last_play'] >= 4:\n",
    "        churn_score += 1\n",
    "    if user_data['last_7day_activity'] <= 1:\n",
    "        churn_score += 1\n",
    "    if user_data['play_count'] > 10:\n",
    "        retention_score += 1\n",
    "    \n",
    "    return \"Churn\" if churn_score > retention_score else \"Not Churn\"\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "print(f\"Generating predictions for {len(prompts)} users...\")\n",
    "\n",
    "for i, prompt in enumerate(prompts[:500]):\n",
    "    try:\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = {k: v.to('cuda') for k, v in inputs.items()}\n",
    "\n",
    "        output_sequences = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_new_tokens=10,  # Reduced since we only need a short response\n",
    "            num_return_sequences=1,\n",
    "            temperature=0.3,    # Lower temperature for more focused predictions\n",
    "            do_sample=True,\n",
    "            top_p=0.9,         # Add nucleus sampling\n",
    "            top_k=50,          # Add top-k sampling\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            repetition_penalty=1.2  # Prevent repetitive text\n",
    "        )\n",
    "\n",
    "        generated_text = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "\n",
    "        # Extract user_id and get user data\n",
    "        user_id = prompt.split('\\n')[0].replace(\"User ID: \", \"\").strip()\n",
    "        \n",
    "        # Get user data from the prompt\n",
    "        user_data = {\n",
    "            'play_count': int(prompt.split('\\n')[1].replace(\"Play Count: \", \"\").strip()),\n",
    "            'active_days': int(prompt.split('\\n')[2].replace(\"Active Days: \", \"\").strip()),\n",
    "            'days_since_last_play': int(prompt.split('\\n')[3].replace(\"Days Since Last Play: \", \"\").strip()),\n",
    "            'last_7day_activity': int(prompt.split('\\n')[1].replace(\"Play Count: \", \"\").strip())  # Using play_count as a proxy if not available\n",
    "        }\n",
    "\n",
    "        # Use the new prediction analysis\n",
    "        prediction = analyze_prediction(generated_text, user_data)\n",
    "        \n",
    "        predictions[user_id] = prediction\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"Processed {i+1} lines...\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing prompt {i}: {e}\")\n",
    "        try:\n",
    "            user_id = prompt.split('\\n')[0].replace(\"User ID: \", \"\").strip()\n",
    "            predictions[user_id] = \"Error\"\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print(\"\\nPrediction generation complete.\")\n",
    "print(f\"Generated predictions for {len(predictions)} users.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0007D808995A3A3F9A061A185D0652DC854D7883': 'Not Churn', '001027BFD879422D2F6274979EF168C89BD5D079': 'Churn', '0013E33812926190BBD0FFA29917C797CA20721C': 'Not Churn', '00158208B67E7A227CC59E9FD3585C517C56E2CC': 'Churn', '0024610E1D72A3990D1F6FAC362C2DF11DF6164E': 'Not Churn', '002711381E686D2B35513BF959AF844FECB15B6F': 'Not Churn', '003B0A44E393B8C83D047AB2B4C908929862F2AF': 'Not Churn', '00448EB3FA9DC0ACD75842246BC6E2DFC9A21B99': 'Not Churn', '006A50EEC9BAEA0ACF020A72492207658DB8EB0D': 'Not Churn', '00A235963BB1F98F59CD4766B732EA874A824F19': 'Not Churn', '00E9D46AD6158CB1309ABC8B474AEACAD4E54E41': 'Not Churn', '015935F89271D4667822DE51BED57363A66AE2E0': 'Not Churn', '0172E50731BC759EE6BCBE4C3FEC16FCC7E845E9': 'Not Churn', '0190E5BA8BC63BDDF98873B7CEA208FCF994331C': 'Not Churn', '0199CF16165723FC6C27B7FF919AC2EEB70C5A54': 'Not Churn', '01A2DE223289C285F9A4224D997D7689DF208D70': 'Not Churn', '01A5A215AAC1141E03ACB26BE8E6B7F528D43B0B': 'Not Churn', '01B9CD994711FE21BB766533572C177FB9BA0EC7': 'Not Churn', '01D6A8CE07D46F15CB51DAD8CB6680FE4D3EAB58': 'Not Churn', '01F2458863F741F4C4943F5D7E49D38B780EC02E': 'Not Churn', '0258E7AA2AA6D6B528109D544F3CBDBCF795691D': 'Not Churn', '0297A853BA2B2713B46C0E2A0683023877C96AFF': 'Not Churn', '02B1B4B44A9E2EF7008B29B74E132705A510F7C9': 'Churn', '02BB962353D77FA28D712FA5EB30EF2AA6360718': 'Not Churn', '02C91D1C07B45FBC9DB80C4891F7153AA32D46A7': 'Not Churn', '02CCE87C2B540041AD5FD02AAE29E8BBE66E0973': 'Churn', '02E1DFFF9E656938D9CACDDA8EFDF1BD1D5AD16E': 'Churn', '02EED2B4E033ABF3F29D685C513842C1F07E4C56': 'Churn', '03239773EA6D8979B40884B6AFF581A17CE9994A': 'Not Churn', '03360753995DA3CC1EEE6782F53A108B55835792': 'Not Churn', '0340E84BAB44333786EC0E9FE93C0512D6159F54': 'Not Churn', '0349BB9E32B1AABBACE91F774749E7A33B8C231D': 'Not Churn', '0350B1AB9CE3CA1D3289FB62974563681B2243A3': 'Churn', '03712B7E7A9EAD1C4D89859430D92EE2F31B84A5': 'Churn', '0399A21E0636B725B15529D41D9349127338E25D': 'Not Churn', '03F1B1701BFCB2F33801904BEEBD09A510037C7E': 'Not Churn', '03F8B4A539365892B91716F1540A2D326F7E020A': 'Not Churn', '04256FA4432B67935CFB7238D4EE88F60D2783EB': 'Churn', '042CECA058D023F2F206779B143E770240271F3D': 'Not Churn', '043ACF235CB173485462CFC6F33DBFB633077DB3': 'Not Churn', '0463C0EB2F288C5FF51F22024B8BC1C67F254D38': 'Not Churn', '04680B7923F9A82FBA741272E9512F9A9DC06374': 'Not Churn', '04689C265B75B1BDCDE9061D80E1B71A49857D78': 'Not Churn', '04B2BED243B7BBAE15C75157AA42F0C5AA52E8D6': 'Not Churn', '04C7D82E0953A78670573E5BCC9B0118AFDFAED3': 'Not Churn', '04F4B97A7A3152AC855DECBD864ECBCFF8C0014D': 'Churn', '04FBA3D5765401B78E32F40DF408399A6EE1098B': 'Churn', '0560649FA3490C3BFBF1CF4322CB53D7D54FFC72': 'Not Churn', '058F166458EEF256FD62EDDD3B33CAB3BCC53112': 'Not Churn', '05C04829ABECDFFEF00703E9B73BD65325274AF7': 'Not Churn', '0629088ACED8B279357F96DFB90F0C9B6191B645': 'Not Churn', '062E6D5EDC8D4A248C625B1A1836C7E1C87C58E1': 'Not Churn', '062F51FD011EE84C72B3885BF5A55CE65EF0469F': 'Churn', '062FA3BCFF49AD2D4AA3C7D1BDFC7B6947DA8B9B': 'Not Churn', '0666D0EA6BBA99CC231294E6DEF3A59F350F94CA': 'Not Churn', '069329D2F7A42283F4B461B4E1976CF201A92F39': 'Not Churn', '06A8B9A6600515BC788930E9D1E067A0FD36DC2A': 'Not Churn', '06BEC9092D587C0656D92EE29EC04C0A12CEE3EE': 'Not Churn', '06C49578377A32630DE8B015945F3860F99A1A60': 'Not Churn', '06C923CFF70810B9989CB9E06EFE3DDD42E30648': 'Not Churn', '06CBAA214541A7AB2293F813CD017C028A1BCA9A': 'Not Churn', '06DBFDBD3C1050D87201614F1CD1094CA81EA3B2': 'Churn', '06DCEE3396468E17EB723CF1E775D1AFD411E099': 'Not Churn', '0701553403365A4A31FFF51A990DEC83CA769E73': 'Not Churn', '072B01DEFCC30A012FD44E08814E482FC63E4131': 'Not Churn', '07430C993DDAF1AFFFBFF47FACFA0A192033E253': 'Churn', '07B4C5F6B8E68B41D746DB3A050F56A6A3EE8CCB': 'Not Churn', '07BF3DD088D4CBFDC6A01435C1A9B47ECCDDA90E': 'Not Churn', '07CB4AA95819DFE5784F88D63866F226EEDB1374': 'Not Churn', '0806D8AEFB41A096271485540EF04D253B594502': 'Not Churn', '080D6F0CC24E728E82C64919424831B41546BACB': 'Not Churn', '0815286C243F480D4471E7A6DF7841D3F89850F5': 'Not Churn', '081A5687826E311971C8951A06D0201D60A37E91': 'Not Churn', '0821CCCE182C9D844E6BEDE82132B34BED68FE83': 'Churn', '0830DCC7C5280AAE3EFA87592D4B71618425CE0D': 'Not Churn', '0863EBEDF4F107E994F7146119C1D917787698E5': 'Not Churn', '08755C940C6A509F36E664E2FD332FFB7D7ED798': 'Not Churn', '0879A08C2EF6D4BCC19A9E8EBBD2592444743FAE': 'Churn', '0893F5EB1E40E4A8AA4C992542B819D87F520FBA': 'Not Churn', '0896668337FA62E94767BF8E6C07054C04E03EAC': 'Not Churn', '08A1A2C9612850ADAB01699F07D9D26F28CA67D4': 'Not Churn', '08B4C43E5780A9EC88FF738E6A769004D159F7AC': 'Not Churn', '08CA318FF90B6A19F8647337569627574CFEF976': 'Not Churn', '08F628DB68C457329D4307214FBC4273526E70EB': 'Not Churn', '090C7D84DAFBE46AA85FFB61F5B23196C9D5E3AB': 'Not Churn', '09196F385E563D03637BE34F9ADD8AA1BA3C94EF': 'Not Churn', '091A5D12B66A6D0B2F7CF2B7AD244812B1849C21': 'Churn', '096ED54E6EDE1D37807DF89842718F038300C3E1': 'Not Churn', '097D297D853158AB4FF559B105E00EDA1CF57E92': 'Not Churn', '09BD8F29CE31CDDF1A3D69CDA7A55F57F7B3A3EC': 'Not Churn', '09CE35812F35CC04AF61BACF302D47CB64647B30': 'Churn', '09CE95ECB347836967DC151E7C3A3CE543676686': 'Not Churn', '09DCFD60FFACEAEA9A0E014650AD2FE28473AD94': 'Not Churn', '09DDC61A840570A8687FEC10059E201BB2A94EC6': 'Not Churn', '0A2531E76F2C4E7689462DD50BE37BBF853706C1': 'Not Churn', '0A53D2F6A5A4A1D0B3A3F5C359C149A42FAD5D63': 'Not Churn', '0A55A31369F6F5C9DDF9E6A1D41368BEEF7F88CB': 'Not Churn', '0A742CEEFCE5DDC8AC47A085DCAC08AE0A01BC6C': 'Not Churn', '0AAF67C49530FEE15CE493F30F008EDE2BFBE1E8': 'Not Churn', '0ACDCCE5E7F4D9BB51FB641C40761DC838968182': 'Not Churn', '0ADC087FAC323579D6ED796EE9A8F82F9DE6C1B8': 'Not Churn', '0AE7F04971508C9C58CF7BCAA8EC3AD202AFC1CA': 'Not Churn', '0AFB5370DBE5CBD9A71BDA3E52A5DBE50557931D': 'Not Churn', '0B0A9D60E2E9A21F6FF8565FA9E7C68EB1B12E56': 'Not Churn', '0B203352AC3ABB0DCCFE2F410B31813877B8DAC8': 'Not Churn', '0B4D1423E0E07D2F3E642BD701B9050F4B9E4A49': 'Not Churn', '0B5BABFA3313F36B5205F81EDB0A3C777D7AA5A0': 'Not Churn', '0B67C398D6012718A94482A0F415DF45EAC56D9E': 'Not Churn', '0B6979F0EB9B63B97FF2623774F251A651BD7437': 'Not Churn', '0B6EAC5C6834263C9FC5275D5448CDB0FB93BF08': 'Not Churn', '0B9BD102AF661DB62E831E4F2B3032BEB21D18E1': 'Churn', '0BD1828BD48310F2D69649D454E1ECEFF1B7AD38': 'Not Churn', '0BED873D1AB820DA08E5E78D024185596EC3FA74': 'Not Churn', '0BFE10B040D68051471B3B96D2BC4DF77617B63A': 'Not Churn', '0C028B598CA74781B3F366D84D17BDFA3FB823B2': 'Not Churn', '0C4F1D37D25BAC7EABBE35A95FC8BE6A97D3E691': 'Not Churn', '0C5E522F2346C63AA85B3D606BA299E32A858331': 'Not Churn', '0CB8E010B9F5A41EFB798923DC337D80D98CA851': 'Churn', '0CC95BF0EEDDB175B48B43834FE543E1D55A7C20': 'Churn', '0D24CCDF875362157821D1935BA35AED4A8FA414': 'Not Churn', '0D54DC911CC0E7B25AD5E5870047398203D7E972': 'Churn', '0D7D8F9D281CB5ABD30512A0197E3FFC28ADDCBA': 'Not Churn', '0D7FF12CAF4EBF80D0B2D587B0D752581BB7446A': 'Churn', '0D8F788479C40F2F8FE21F4B639D5DD9C38FAB3E': 'Not Churn', '0DB7680339C0EFF577F9595717C9371A97CF6145': 'Not Churn', '0DBE4771BE9817F4CCF029116E1B75D4724725D9': 'Not Churn', '0DEF705FEF7F3F204A0200B5D7003FA41DCD6AC0': 'Not Churn', '0E326CCC50706ACD8E4FE44362A381426FEB5C4E': 'Not Churn', '0E3291DC2DCB3D5106D31B9D559DAA779C0C12A5': 'Not Churn', '0E36E6FC086C685DD2B857C38D8D38C2C64AA59F': 'Not Churn', '0E4F87D15C422B6A3A003B3AAB768CB0C9411CB6': 'Not Churn', '0E999534B58E8965CE549E45DF0DC658C86EDCA9': 'Not Churn', '0E9FA74141A753DE007FF0DCB377F5C41FBE81E3': 'Churn', '0EB9B7CF09F467845C92A952EAC496C204844D4F': 'Not Churn', '0ED205B57BD48FACE65CD1208EEB89E8121DA372': 'Not Churn', '0ED8BAF487AB520644AD2BDA480E7E57FC171850': 'Churn', '0EDE3C6382E426AD76280C928C8F808A58FF1C84': 'Churn', '0F2D8AE5BF996AC60455CF2A9196B542FE47D505': 'Not Churn', '0F331787868E3BFF89BEE3B9737C83034BF816C1': 'Not Churn', '0F42F3F759A4377CFA9366A7D817CFA7F23B56E9': 'Not Churn', '0F438F6E3045323887113B7DF827FB6FC0E04375': 'Not Churn', '0FA189527954E663B65E24BDEE9E46490CB9F849': 'Not Churn', '0FE70EC28DEE33A09EDE4C45FA0C7F34B0FAFD64': 'Not Churn', '0FFA4EC83AD2AEC572B966B1971452E0831BE687': 'Not Churn', '1005EE1EE07E470A7914D95DD47182C82F6BB22B': 'Not Churn', '100C92F90E2BD8A5B2B366E8DCFA2973B55DA3BA': 'Not Churn', '1050E1328767BD3900A94CFFC61CC49503783A18': 'Not Churn', '1092C4F4B49E452FBC0CB2F33065500F49B3A527': 'Not Churn', '10AB078B1780ECABFCE2485A6A7B10D65D89B6EA': 'Churn', '10E135CF44548B3D78F0AFFEEC6A6A28ABBF1DE1': 'Not Churn', '10E391F4F6576CE6C213EA0C15429E107F5A984A': 'Not Churn', '10EB71B470BFBCDBBEB90CF363EE9A6B6CD62D90': 'Not Churn', '11232D362617CFDC2B960068B2155E7B4D18C814': 'Not Churn', '113DD750521C5737A4D4C8F2BEA1879DD605F70B': 'Not Churn', '1154EA4368B8D26522BDB7D025E45B6C14AF25F4': 'Not Churn', '117FBBB8365F45804BB21E47D310DE8A2C6D902D': 'Not Churn', '11A1EBB6F914DC52E41D787BDF205271243F7254': 'Not Churn', '11F28E93C57C0F88FF9D8D9427CBC3C2325F46F7': 'Not Churn', '11FD1C5C95089C0E604521AA99FAD72474FD97E0': 'Churn', '12358EC38678756778E64DE2EFC16737B73BDE01': 'Not Churn', '1250870915C1FF10DAF257BFCB3A1B366818D706': 'Not Churn', '1271D336B4D668D9C0B8684DDE41F3F2ED6BEC8B': 'Not Churn', '128669F012B2CA8E3F35784F9941DDB1F5B75004': 'Not Churn', '128E0A2B028F146877B35465C16560FB088586B8': 'Not Churn', '12B2AC92021B95122B96EA1A6B45E946EDB145EE': 'Not Churn', '12C39D6EFF8D30A6871F01AEE1FFFDE51BCA35CE': 'Not Churn', '12CB44139DC6BFEB884B80BECABE24D689DB4A2F': 'Not Churn', '12F33E5B73FFC7BD8D823B90C0D065A86E4FC4CF': 'Not Churn', '1386FA009422400E1095640F8A86B4F17BE3420F': 'Not Churn', '13880F6C663014405CA2E925A89A6661BD2FAAE5': 'Not Churn', '13D8E1219E14C3E3F6FB3B7408916B1C06D5A7A7': 'Churn', '1401C16AA18479AFAD936D88697E8B55DF694E50': 'Not Churn', '14043B14AB21C805710E1BD68B944B7194BC5AD9': 'Not Churn', '1449DC3D91D2B56F31D97893FAC28B1266A03821': 'Not Churn', '14536C2EC45AADEBC57B412BF6B0877A6AFDE9F9': 'Not Churn', '1457E301F039FDEBB2D7476B80740BCBD6CE60DF': 'Churn', '14731927802EDEA611152CFE933B8C353E98120F': 'Not Churn', '14760412B71F60ABD52A8D3210933DADD8D2E41C': 'Not Churn', '14BDC3DC8B4BB757D23715EC58B2979DFDD2115E': 'Not Churn', '150E8472EF1B0165C235743A8A6A023C8E739C77': 'Not Churn', '152246ED61BB73B5DA040DFFC23806C2EC2E4629': 'Churn', '154417A845BC1907C460FF4A03FCE9F39660BE24': 'Not Churn', '157F1D76A3C0216F614A8B40C666D8BB5CEDDF00': 'Not Churn', '1586C0A8606E99AB50459E9BC3B3D494BDFFB47E': 'Not Churn', '15AF97F6811BD929C5B785F20A166C7B2EA4B965': 'Churn', '15D58075072C616CB88DD5389A9CD30C50986738': 'Churn', '1630B0BE8ED75390A48361346880D9D761BB7E3E': 'Not Churn', '1642239E902BEF338F115E4235F1504F2CD5323C': 'Not Churn', '164CFB70881B327D4785EE413226F860FD90FEEF': 'Not Churn', '165C1008D708C6B809BE243037756770FF77531E': 'Not Churn', '166A0F4D9FA397CF9FF6AF440BBCE9E87C339981': 'Not Churn', '16A4CF8445D5DD39EBE8A11B4E1EFC521E167262': 'Not Churn', '16BC6599A6B30767BEBBA8F608B38230678B7F1A': 'Not Churn', '16C3E66D4089BA6E2FD536088A11AB374A3BA326': 'Not Churn', '16CB285910E6F21486ADF1529DA409675E0869E3': 'Not Churn', '17247389F0F5802DDC5BA7BC0A6B6B64FCE1F01C': 'Not Churn', '17316FCA962487B812E1E31A898F69975A4EE80F': 'Not Churn', '174D18DFF12ACE26A7549F661A34E9094AA14689': 'Not Churn', '175BCF22D064E5CFEC7223192336F025350190A8': 'Not Churn', '177076BD09E41FDF6A6CE7F436360609063F7045': 'Not Churn', '1785FF14789E45ED84BFAC2E9A684CB1E806A241': 'Not Churn', '179D61F6DF68ED0453B00BD6657794F57E0FD421': 'Not Churn', '17A74314BDEC2181364B33F8386C81E845DD0F70': 'Not Churn', '17DA73B925C388F794980E5D9A5A79517FD617C9': 'Not Churn', '18917A8D7186E3055A2542D167854BFB37CAA3A2': 'Not Churn', '18AE658203E96EDB3649BC69ED25060EF023593B': 'Not Churn', '18B130091DB6ED07AECE1DF9BEBB828F0E244AF1': 'Not Churn', '18C6995AD9EC8452A2C1F4230A3B6C0C8400ADF6': 'Churn', '19078D33A6AC08BBA5BD0452B09A06AB64D07B37': 'Not Churn', '19184A1B14FD7808590E476F0857BA18C8E5C596': 'Not Churn', '193732C176CE798FE521C102610DCCEB5550F74B': 'Not Churn', '1946148681E2EBACFF938BC97022834A600E0D2C': 'Not Churn', '1966033741E55099481AC9D6B104F26755DF2ACF': 'Not Churn', '197374F617174B2ED2C52FB7D20BBB1D34887CCC': 'Not Churn', '197E7159509D4D01D553DC1084962F67F943B85F': 'Churn', '198D13FF8BF5C13292C796618C0CF44B4F2B72C2': 'Not Churn', '19B573695411D804D91BCBCC91C561AB53E0FFA3': 'Not Churn', '19D955044789AAC8E61DE9B994C447C1B0FBF9B6': 'Not Churn', '19DE202FA6E5FF2FD4CF51AF91E71DF94C3CEA04': 'Churn', '19E781B82EFFC54A54F2E3F782E92F5A25AE0775': 'Churn', '1A0AAFA96DCFB54EBFCE5038EECD45B7D5B9858B': 'Not Churn', '1A2A2D331744798AD9544BAA8F7764138656897D': 'Not Churn', '1A38E74025A9B0E8E6724DE7A1BDC79A8DB6178F': 'Not Churn', '1A5471DB90C096210157C2B1B39DCF6CE67FD0B1': 'Not Churn', '1A5827C0869ACDE877CE6C5579BF3FD37B2630F3': 'Not Churn', '1A84CB10A09445014016D6893F9989372D659C57': 'Not Churn', '1AAB1201331FE784BA18C297D225B7E4F10D9FE2': 'Not Churn', '1AACB2D6BD9F043B8816288E031CA63F09B8925A': 'Churn', '1AB23440B34D2BB018227ADEC8A8C3289AA08F4F': 'Not Churn', '1ABDE8CCA95B8CD7F7EAE1C9D1ED49A01CE03B26': 'Not Churn', '1AD41AF4CC4D48EB51EC646A3CE4F708372749DC': 'Not Churn', '1ADE01CF464FBED63DB624443D65EA189DA94734': 'Churn', '1AF4306DE3787B6F37C4A2FEA97E7D004302A246': 'Not Churn', '1B0A6E48FE26F87696A882E3285B1FEB9111197D': 'Not Churn', '1B2012D4DD90C68589A5C2E53B0D32670211A932': 'Not Churn', '1B24E37701CF88F32858F2214FDF8439827DA470': 'Not Churn', '1B35EEA9847C11E9094DDC3D17855126AE7FC1F9': 'Not Churn', '1B37124F80EB61F5A1C7A46931096A8961788593': 'Not Churn', '1B597A82FBA9746C35A1CFBAB7DDD07BEF4F81FB': 'Not Churn', '1B935F9109959EC82181419F780AD460C15C61A1': 'Not Churn', '1BB330A06CC11352B225B515B4B1D323EDC4574F': 'Not Churn', '1BBD465D8ADC569D7DBEDC80250FD87CB53C4EF9': 'Not Churn', '1BBDF9E8EC0A31A8FE03D51BA0C37AD693ACCFE9': 'Not Churn', '1BD6667D391CE0C5116C1D2484B3BCE0259FED4D': 'Not Churn', '1C0175151C847B07AEA4885708BAC57B830EDAAA': 'Not Churn', '1C064068BB19569961871D455C2B97F46608A133': 'Churn', '1C15C10A3B57225571CF87E1E5CA97EA623AA415': 'Not Churn', '1C25A94402F1EEDB5F14D69EC04582A2FB307BA1': 'Not Churn', '1C4D9766FEA88225DBCEDBA84B7C5361D3F72875': 'Not Churn', '1C6C8FC324CC209FB78098892E4C33D2BECF95F4': 'Not Churn', '1CDEF73854D4266F2165C5CF7CA2DD7A4B4FB65B': 'Not Churn', '1CDF886CE18CDBCD94BFE6E524915FF986D18DC6': 'Not Churn', '1CED0E358473BF3CE540E17DB58DF2276042F22D': 'Not Churn', '1CF764137F6ABF37D1EAFC1AC9F87418601B9578': 'Not Churn', '1CFA320A3097255E49EA7DD45B2BB00DAC2F669B': 'Not Churn', '1D27B2FEF1F913EF9F931AC763221DAF4926C7DF': 'Churn', '1D2A795D9FACADF64427B7006281D01C7CC39145': 'Not Churn', '1D31F8FFFAFD3130BFB872A1C4F050DF87297D2B': 'Not Churn', '1D4756C938E8C25DAD90CC296C8D9DC249D4F0F7': 'Not Churn', '1DD41F488450B0D6D51EB0967B0E855E1FA95D2E': 'Not Churn', '1DE6165C815E351DDC8666D2B1022979DEBC133D': 'Not Churn', '1E151A09D80B2460DD306CA7E51E548F6AFC78D6': 'Not Churn', '1E2B9C54856A93C232194B1903675C751AC80E13': 'Churn', '1E2CF4AECCD747773CCD102381FF871DDF6E7E76': 'Not Churn', '1E53C66DC28FB8C6D1A6CE152D97C70D2CA3BC8B': 'Not Churn', '1EBF436FCC86A20012935DFB8DEB43A842AE52FC': 'Not Churn', '1ECC49E52D007E9C53BA66136F579323F3E6D031': 'Not Churn', '1ED64DC20D67EF50713D94923554104893E102B0': 'Not Churn', '1F55D3EDD7424D7E2DE8E2B9523B196B6CC8CF4C': 'Not Churn', '1F58422C0F4698C5CFFCB154A73A548F691F1DD9': 'Not Churn', '1F66C8F0B59086D05BBD9A2F0D5D9B402F3185C8': 'Not Churn', '1F92D557066CF70C604593936CB685061F34C232': 'Not Churn', '1FF383123D0064CEAA303A588DEF232F963AE846': 'Not Churn', '20125B73425064162A2B3DEFA874355E43A5F799': 'Not Churn', '2054DD699DEC20E53B8B8F79E78E0D9D0A95DC38': 'Not Churn', '20B9D9F47D109E6D2DD78889A506E4DB6CBCA42E': 'Not Churn', '20D0D3DD4723C439EBCDB0FA7D9E7063F2CE48F9': 'Not Churn', '20E712948921C5A1A4A2534E2BA627CCAC42FFF2': 'Not Churn', '210806BFAFD4D9D21E1174F6C9B461AB3E9ED9E3': 'Not Churn', '211F81A1A5765B68288DDCB8F134357BE21CDA59': 'Not Churn', '212EB1D8804448CC70EA4737C8EFBE0AA7CDF6F7': 'Churn', '21437C24139B3DD471835CD5A2AD47AF6BAB793C': 'Not Churn', '21542786A6C70C2635FEFF21DC1A642FF6F3AB98': 'Not Churn', '215D92998EB044DAD7720D1193B710B6A87E556E': 'Not Churn', '2176C5FB997B6C116B8D0FF82C20A504687E83EF': 'Not Churn', '2184BD954E61EEE806B8B6F31EEA5F4166BF1276': 'Not Churn', '21966781468CD5FAB794DA16CB6B91D36E9DCBFA': 'Not Churn', '21BD54D6A787633F0C64E6B4F37D64AC7C862BAA': 'Not Churn', '21EA4FC37030343AD6B12968A19E07A084689E54': 'Churn', '222E820A80B1C2341D97CB214B607E23607D97D3': 'Not Churn', '224CE1F915C7FA692811717B5B1027E477CAEEAC': 'Not Churn', '2254E84E6A6D2B214CAAB0B9EBE0BC8930F4807B': 'Not Churn', '226A41A3D4D3829823B4376CCF72D0CEE696FE66': 'Not Churn', '2271C189C8D14E073B5DD8EF377F3EACE8108709': 'Not Churn', '22F4A910BAA63A81386D64904AF540707957032A': 'Not Churn', '23177E80AA2442C9CB25ED7F9FC4C9535E9AF1E4': 'Not Churn', '232659F7F6A215CF1DF71FC1293551F5F1CA8012': 'Not Churn', '232CA3D45F49DEDAE02CEA42E55A636EAB51DF02': 'Not Churn', '235CE2E08548EB962D8D9CC514B2DC6128A7F536': 'Not Churn', '23760C18E775649207E0C1C779FEE940BE2A0032': 'Not Churn', '23FD303E6976253B78823EEF65A72A1D8365E605': 'Not Churn', '2408FFAD132368D49E67256201AD5AC66C0243D4': 'Not Churn', '2411E7E2B9BD5A541DF7B7FE778479BA779F5D5F': 'Not Churn', '2414E6555CCBF021AB5E1D2806930483F5BE48FB': 'Not Churn', '24151854B555BAE24B6637B1B2ED02B3AE0964F4': 'Not Churn', '246858E8A7E9B9EFE5237874D811DE74DC8B87A3': 'Not Churn', '249B61A49D363AF2017C46A2D4CC8DA8ABC61C9F': 'Not Churn', '24B895FD0A8C9CC161FE698E93137C76B20F7221': 'Not Churn', '24DD77974DE6637A415CBB416E7CCD07C208E1A2': 'Not Churn', '24FEDEA7A9C41B503CC8189974910335DA985C4F': 'Not Churn', '251FB7C2A3F28D7282F741BEC20EFFC958F63133': 'Not Churn', '2592183081044327B2D8880FFD4CDABBCA738363': 'Churn', '25AF2BC2A702D4A3D3F8B86610AAD9DB40F76D0B': 'Not Churn', '25B998B3BE925F3CFFB653FAD07794147AABB5F9': 'Not Churn', '25C44E67AB1DBF75B8C19F9EB5D3CF5F4F0F1F36': 'Not Churn', '263EDFD0E81228AEFDC85C7505C5A16D424422CF': 'Not Churn', '2674EE00C4CDCD651AC06B27DAD2C334E5BDFD93': 'Not Churn', '26D1D33AC0BF393B36412D14E1C74CE618C57AB5': 'Not Churn', '26E0594C2A7F7715E253B4957BC4DB90A73947E7': 'Not Churn', '26E306A2A1CD7FEDF49E8718A4F5D497127DA82D': 'Churn', '26E812CE0673412795A3F62FEEDABE032F8AA118': 'Not Churn', '270999EB67FFDEB9033600234643090E57798867': 'Not Churn', '2745624572C7319AA1D19F4F548E9D1134FFF15E': 'Not Churn', '2760BBBB5A8E6C25EFB6CA935C84B9E9EEC44D6B': 'Churn', '2782E3337E8B0AA9881B612B0840C8C0DB27AD81': 'Not Churn', '27D15B2CF3D0A01BA05D5B9E264C97A69F117EDB': 'Not Churn', '27DEE130C84D065329A7CA97F6D333741AAB7B86': 'Not Churn', '2800DB1CD1D4C7F3E1131FCE9C151AA10DD447EF': 'Not Churn', '281D481FF883D125C059F697B6C244F6C82C54DE': 'Not Churn', '286A8F3EE1B09F1EB25FD04147CD163556DAFA30': 'Not Churn', '28A02FBDE87D9B50290EA3DE7DEAFB362F93D128': 'Not Churn', '28A63F4A4E88C674EC5B2124C24868A81666E7F2': 'Not Churn', '28A6AB8208354E05BDA4E418C09529271532BAF5': 'Not Churn', '28CA40E1E58143349ABF816BD4BC0D7D3E8970AD': 'Not Churn', '28CDB9062885A4A1938EA3F065355ED836D9D3FD': 'Not Churn', '28F609EF9E73AB2D88F7092927ADE7E24FAB1A9B': 'Churn', '296744A2E25C16B38A5A45767D20AC8F0E4B8093': 'Churn', '2996A7892284E8BCE2DB44B7525B50C4F6B86A6C': 'Not Churn', '2A1CB15DC59B51C8462017FDC55B0447F4405D0A': 'Not Churn', '2A43AEA77D9FF6A7922F02D2C8A9FB6A2443F5CA': 'Not Churn', '2A4D2D986E39B78D471371A3EE2A9561957785EF': 'Not Churn', '2A85488A9B6EA1B2D8BBC187E461E8435A2D911D': 'Not Churn', '2A873EE6C971C72AE0DD5647DBAE0E72A99956F7': 'Not Churn', '2A8B4D928C08012D36246E27D61203EEA33C6CF7': 'Not Churn', '2ACD52C13419DAC618A50A2FEF6450F39C4CADEE': 'Not Churn', '2AF8E3BCFA472BE3446B2E896207C553F0B42BA5': 'Not Churn', '2B0EC589D402525C8C92712964B7CA39B9B16347': 'Not Churn', '2B4ACFA3968F9CBDFF8228290AB53BF805B73F63': 'Not Churn', '2B54CD5CE8200D241890AEAEF629AD8A04679F2A': 'Not Churn', '2B67145C70EF3C38E0CC66EDC9B851BF0DF178EE': 'Not Churn', '2B6BA2D7A671C981B71542B819CB36A0A1AEC5D1': 'Churn', '2B86ABBFE3DFF5531761818EEF8DD0AFBD9A2BA9': 'Not Churn', '2BBCC5110A3D5B378CEC345AB4F0B8F4E5D4714E': 'Churn', '2BC250E49E0BD0A2353C2C2747EA8934934BC8C8': 'Churn', '2BCA25A6B37A53E40A95C3B42DC7F40F5225A67B': 'Not Churn', '2C00DE7DA46B56DAE7C177FFB98BEEC2BECA8BB2': 'Churn', '2C19CFC40AE199133BD6B9298114E9F5AE16BFF6': 'Not Churn', '2C42755F6118CC9B27D4ACE96E2B9915AE5A50DA': 'Not Churn', '2C45DD24DB4B733382FCF9497886FB43E847B5E6': 'Not Churn', '2C525AD60D1D190DBB17DA9E0CE71B5EF63C2481': 'Not Churn', '2C5B46FC810D38E77AFD40D9443A09EA0263FBC2': 'Not Churn', '2C7B513DD7F5CC34A878A0FE34D21C7C348FA2D4': 'Not Churn', '2CB564003BD422B6BA385CED69BDF606824BFD00': 'Not Churn', '2CCD2FB079607E5D755EAC2F94DEB548B54CBBD5': 'Not Churn', '2D605A9D8B5DAC395BA0CFC8E706590E147CD4BA': 'Not Churn', '2D666BE873BF96F435A4B05DCA2C488300932F16': 'Not Churn', '2D71D6A22A129C1841FD9B036C4B7852E5B3FDCC': 'Not Churn', '2D9F01E52746A1F342FD36AE84B1F9BE7302167C': 'Not Churn', '2DF056FF43AB7DE47FED0515616BF050B7A7E9E1': 'Not Churn', '2DF37ED9A6C5603075FC00D919D866E1B9700BC0': 'Not Churn', '2E11199DC1642DAB399F12E23D245B14DE8F9187': 'Not Churn', '2EA80A84386853D75C723D3F2EC1BD72B1DF7083': 'Not Churn', '2EB17B8CE25D30F11CA5CE06668DBB04B3D80019': 'Not Churn', '2EDCAB7A42537F3F84E7C18B9C9CA84BEBFF169D': 'Not Churn', '2EFB567C253E8CF3A6D4968E6DBE458C33EC2C58': 'Not Churn', '2F2A8FDF30759879485DE5E71298E6D7C4D0B972': 'Not Churn', '2F93CAD0AA8DD54A18638EE8CC347E6317DF7F20': 'Not Churn', '2F98C88F11094661F71719250F73EAF6F06D0A46': 'Not Churn', '2FD7521E9418193D7F5D0E1CD9443FB922DCE707': 'Not Churn', '2FF04BB79DAD1D2913B46DB48DBDF89D11C72E22': 'Not Churn', '30016BD14DC05B4CC4C4356802D4C27237CA1D99': 'Not Churn', '30307BA07FF8B2144114DC759862A1C062FA48A0': 'Not Churn', '304445A5AD754A893E73F8129B35B44734CD289F': 'Not Churn', '30CAE98C7537E93EB301614EBE5123FD16F618DA': 'Not Churn', '30CFB2B81DBC832D50F2C89214455E3581CBDA91': 'Not Churn', '30D026F1DF2824FC484183DB9380D0C9D29B54C7': 'Not Churn', '30EDD72F2412AC91A809C08D8414F113279BC57A': 'Churn', '3119D9C4C78E66B6F0DF7421C6B54E30B8A2C790': 'Churn', '312BE6E1A5E82E2C50726038F216AFB4EA8BDC29': 'Churn', '3176F284C2D622E3F935D1971CD776D4F0D7EA17': 'Not Churn', '321A8E71E547432D23D7C4498D1C7E0BE95C3240': 'Not Churn', '322A7DFA5034EB88EBCB604F3BD6F16CAA35E44B': 'Not Churn', '323AC4F6EF04169E651BFCC5414CE4CD0DFC605B': 'Not Churn', '32476A6A5A0FDCC09457E81F12EAD08B298E84F7': 'Not Churn', '3263D7D735283DC5490DC2AF7469FE320AC9F06D': 'Not Churn', '3275F396C08895C46B1427D9378E2D9E06C7B262': 'Not Churn', '328CCD00ABF357C214D96CEE72C7AC615377A0CB': 'Churn', '3306BFA7A6B45EA5D3E5504391259366665535EA': 'Not Churn', '334515D2A3085332F1089F11D31D8823A28B5271': 'Not Churn', '33A026F95742F2E643234E89F2D0E6FB46F3AD2E': 'Not Churn', '33C0F426DBD1680D477AF5976B621E870D8AD089': 'Not Churn', '34114DC6363D6F2539E4D0B2BF1B11872BDDCBCC': 'Not Churn', '342339D159EABAA73D88096EF4A81629EF451464': 'Not Churn', '3424C3417CAE072EBC73F2BDDF308F6886B8A7B3': 'Not Churn', '347F5ED52CA25C6C4957BE619B2F1284E77F3727': 'Not Churn', '348CD6784907A3E07F00B04B594F6FFB1FB645A1': 'Not Churn', '34975728A8DF31CCD69EB2B91DB0A9880DE8220D': 'Not Churn', '349CFE43AECBC1388F63F7006474DBD84091ECC8': 'Not Churn', '34C7568E6D6B5CEB0B50C2E8DCC53D9FFDC8E35E': 'Not Churn', '34DDAEDE5B69681B7932B9B6A96623AEB3965E07': 'Not Churn', '3502C8E72F116157D4210DA0E494BFB7E82797C3': 'Not Churn', '3551B2E252CCFEAAAF4C59789B9EAF2ED7C02246': 'Not Churn', '355A1A3417874859EE026CFFBC96B3941CD0CD6A': 'Not Churn', '35D8845678581B22DDC67E559324A9BDDE3E5F84': 'Not Churn', '35E89F597970FB6F45BC609D61A06E63F0CE4A26': 'Not Churn', '365BD423111CE1478470C8A96AC4C4B4BA78C227': 'Not Churn', '36F77E5EC84E6AB88B74870D74B0BA590ACBCE9E': 'Not Churn', '375C9459EB6FCBD204643B3BA7BDC27EDE516066': 'Not Churn', '376DDCFD0AB17B19CEBA31CF8F93016221B0A1EF': 'Not Churn', '379FA2A74774FBA8AF6182F810111848E51C72C4': 'Not Churn', '37ABE294BBBC2684E7F1BB0D075BF7102A867ED5': 'Churn', '37B9F74F4BD05162792FE4E0CCA787FF2C8F414B': 'Not Churn', '37D9971206C04E1457A1C8283CEBD3E1510A2F4F': 'Churn', '37D9FB61A886CD7931927CD02C4D945D199916C3': 'Not Churn', '38066F4B9752151C3CF6A4A065B2492D579D5CCE': 'Not Churn', '380E6A7860EDE97962745E034CD6E211A64A0FFF': 'Not Churn', '380F62A6744359C2242CC95E373B29346FEC1D3B': 'Not Churn', '385862D2B001EEBDD1D463D0A3A01A4E4C2D19BE': 'Not Churn', '38D85414BE31508E2B637B80EA414A3930F9EE10': 'Not Churn', '38ECDFE075E01765B16ADD9CEBDE7CD8DDD2F7EE': 'Not Churn', '3905118880C8E99ED593CFC7402B74B60A774564': 'Not Churn', '390AF84FC3C85FD4089EEF45570B09BBC4158842': 'Not Churn', '39141FA31DDF386B571C1E96ED63EE3505499937': 'Not Churn', '393F2CAAD332108187F3838987454911386EBC96': 'Not Churn', '39576FB36945EF6D01BCA8BC0FFA08783C669C8E': 'Not Churn', '39761D5D611B6304E438E7B1E026236A220A552D': 'Not Churn', '398545C9C52BB2362DA6678009AAE871FFF67D52': 'Churn', '3992258F1DF6CB0C3914663F7692898B7DB762F3': 'Not Churn', '39E327ED9BFEF3FA77FE633A606A8E41D4D232C4': 'Not Churn', '3A38F18E94044F3CCBB148253AA60C966604358E': 'Not Churn', '3A79EBB31AE5DF59EDAB90C9D3CA8AD56230D857': 'Churn', '3ADAA67BA7EF6E6A2C899D68D127FB6368351EA2': 'Not Churn', '3ADB61AEFF5476E6A6C594AEAD680E35D7C92F97': 'Not Churn', '3B55831F4499237C9C4951C4E2F6AF574EDA1938': 'Not Churn', '3B86CEDB0CF032777C567FC01A39B4753C2262C6': 'Not Churn', '3BB0082F71642F9C23F4D89D2D85FBABB1FF2290': 'Not Churn', '3BB406520FF75F753AC3BCB5BB01BEFA3A1BD416': 'Not Churn', '3BD86F67766B42DA70465F991B5CE45295F0229A': 'Not Churn', '3C04AE85DFF9F18CEF5E07508C8158081A8F12D2': 'Churn', '3C4E63CFDD67420088EA7776127271EC26F5C75F': 'Not Churn', '3C6376B877C8AA442C2EFB9F8B30C55DEDA92798': 'Not Churn', '3C93EE7B904737C97BC1DFA11D9B67CDB187BFE0': 'Not Churn', '3CB91D3B56CBCAD66B054186D2EEF220434E2169': 'Not Churn', '3CBD38EDA0010F39D63483C61BDBC6E49A4B7774': 'Not Churn', '3CCDC6FF2564EE035766BEDF94018B9AE1EE435D': 'Churn', '3CCE5CEB938281E940BD1B42BD904FFB5D2DFE85': 'Churn', '3CF609AD5F29E340074059F1BE9F8A0F40383695': 'Not Churn', '3D051B1146BF849DC32D45E739FCBCF7C8C08928': 'Not Churn', '3D28DCC1B61F11DA669ED3DAEA8CA00684AA3660': 'Not Churn', '3D4EF12DF780DE7FFB5FC0ABBB5BC15CF6588286': 'Churn', '3D5222F7E1FAEE3E2704ADA3A6FB9129B214B25C': 'Not Churn', '3D6057654135A5BBD4C1E22016D81300B1DF0CCC': 'Not Churn', '3D79C7D8C0D47389837BD58FEB2B7FF9BC453C59': 'Churn', '3D811AE07146FA37781537DF1F4473D26AB5972C': 'Not Churn', '3D834095255ED689E053729E84C153DB9A17FF2C': 'Not Churn', '3D98ACE6AEB07AB52F0F88D4DD314F2C820DA915': 'Not Churn', '3DFEA400E10B93130288A6862019101F13324CCF': 'Not Churn', '3E5552DB89D7BB0BC26C55B63E97D218F81D2587': 'Not Churn', '3EA2E5BC625FF271036CE48F4992CF859826B9B5': 'Churn', '3EC4A87ADA282FE871009661C29AF257EB500219': 'Not Churn', '3ECB262BB6341D83C61BFF954B98830493AF69F7': 'Not Churn', '3ECB4A6E8E3D519B18AC426AA1EB1783859E65E4': 'Churn', '3F160158C0AFB7160E86F15A4F6891F008CAA082': 'Not Churn', '3F395C767E74801A5A86185D3F85AE21B941A97F': 'Not Churn', '3F42867837FFEFFAE41BE7BCBF55E31D8B61BE43': 'Churn', '3F6D785117AC6FD531CDD9B5710F95CE93C696D5': 'Not Churn', '3FB99269578B6AC564CED65EBE3983D16A15CC97': 'Not Churn', '3FC5822EB1FC5B4F3373011E5CB3D284579215A2': 'Not Churn', '402A104070A120ACA961E7BFEB63AB845F8E65A4': 'Not Churn', '402B7280EFE5CC96BB6E73C5B1B31A3BD845A9E6': 'Churn', '40357ACBC3EA5CF1347337D3C2212C934901BE01': 'Not Churn', '40E1097FD913661F71F29D7423716485A8265793': 'Not Churn', '40E834349F4F67558717AAD28857A3F03DE61F31': 'Not Churn', '40ECA24728D6372E8A9D75F0D513F73012C200FC': 'Not Churn', '413DE91E362D398072D605BEF8131CBCA55E281A': 'Not Churn', '41B408914E5C75BDF7ED08DA6ECE4F601BC5E133': 'Not Churn', '41BF260359C3D75F143B46AD34E089FDA51FD1CB': 'Not Churn', '41C935A21CF7A439154270ED9784E95D75B7D8C2': 'Not Churn', '41D29768FB9FA8AE3CE36BD9F9A0805763DBDB7C': 'Not Churn', '42A9B3AEEA3CC962C25E1A0F4F4FBC512D223603': 'Not Churn', '42AE6163CB9917FEA135C47A2F051BBA85ECDA7B': 'Not Churn', '42CA3F93D344F47762F848CFD79D5AC2342A919D': 'Not Churn', '42DAB60EE2F427C5EC4A44248D0B1912A84BECC5': 'Not Churn', '4304FD86CF5FBCAE7C3DDF5606DADA0E0DCAD051': 'Not Churn', '434B74F44243D6864E8BF81C8AC8CE6C26ECCDF1': 'Not Churn', '435FFF621AD34BD4F8908F9387E8D1D54097A103': 'Not Churn', '437AF8CC502AD11BCD9AC98C4F72C905515DE125': 'Not Churn', '43A2C6C343EE325DE357B5672845A7030EF93DC5': 'Not Churn', '43F072AA697BB74C8627E8C32B06491F29A9394B': 'Not Churn', '43FC102ECB12C095349616813BD1F78AFC2DCE16': 'Not Churn'}\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluate LLM churn predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating LLM Churn Predictions:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Churn       0.80      0.15      0.25       386\n",
      "   Not Churn       0.23      0.88      0.37       114\n",
      "\n",
      "    accuracy                           0.31       500\n",
      "   macro avg       0.52      0.51      0.31       500\n",
      "weighted avg       0.67      0.31      0.27       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "processed_user_ids = list(predictions.keys())\n",
    "\n",
    "actual_labels_df = ds2[ds2['uid'].astype(str).isin(processed_user_ids)].copy()\n",
    "actual_labels_df['actual_churn_label'] = actual_labels_df['churn'].apply(lambda x: 'Churn' if x else 'Not Churn')\n",
    "\n",
    "actual_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "for index, row in actual_labels_df.iterrows():\n",
    "    user_id = str(row['uid'])\n",
    "    actual_label = row['actual_churn_label']\n",
    "\n",
    "    predicted_label = predictions.get(user_id, \"Unknown\")\n",
    "\n",
    "    actual_labels.append(actual_label)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "if not actual_labels:\n",
    "    print(\"No users processed for evaluation.\")\n",
    "else:\n",
    "    print(\"\\nEvaluating LLM Churn Predictions:\")\n",
    "\n",
    "    all_possible_labels = ['Churn', 'Not Churn'] + list(set(predicted_labels) - {'Churn', 'Not Churn'})\n",
    "\n",
    "    print(classification_report(actual_labels, predicted_labels, labels=['Churn', 'Not Churn'], zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
