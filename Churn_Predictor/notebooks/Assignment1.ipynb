{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS1 (Train): 20765 players\n",
      "DS2 (Test): 5192 players\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_and_split_players(data_file):\n",
    "    # Check file extension\n",
    "    if not data_file.endswith('.csv'):\n",
    "        raise ValueError(\"Only CSV files are supported.\")\n",
    "    \n",
    "    # Load CSV\n",
    "    df = pd.read_csv(data_file)\n",
    "\n",
    "    # Convert timestamp from seconds to datetime\n",
    "    df['datetime'] = pd.to_datetime(df['time'], unit='s')\n",
    "    \n",
    "    # Get unique player IDs and split them\n",
    "    player_ids = df['device'].unique()\n",
    "    train_ids, test_ids = train_test_split(player_ids, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Filter data by player split\n",
    "    train_df = df[df['device'].isin(train_ids)].copy()\n",
    "    test_df = df[df['device'].isin(test_ids)].copy()\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "# Example usage:\n",
    "train_df, test_df = load_and_split_players(\"data/game1_processed/rawdata_game1.csv\")\n",
    "\n",
    "print(f\"DS1 (Train): {len(train_df['device'].unique())} players\")\n",
    "print(f\"DS2 (Test): {len(test_df['device'].unique())} players\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating features for DS1 (training set)...\n",
      "\n",
      "Created 20764 training samples\n",
      "\n",
      "Sample features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>play_count</th>\n",
       "      <th>active_days</th>\n",
       "      <th>total_playtime</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>score_std</th>\n",
       "      <th>best_score</th>\n",
       "      <th>days_since_last_play</th>\n",
       "      <th>avg_session_gap</th>\n",
       "      <th>last_7day_activity</th>\n",
       "      <th>churned</th>\n",
       "      <th>device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>51.739733</td>\n",
       "      <td>115</td>\n",
       "      <td>4</td>\n",
       "      <td>0.015833</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.214550</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>010941525590041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>0.014444</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>012345678901237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>13.479614</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003264</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>012345678912345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   play_count  active_days  total_playtime  mean_score  score_std  best_score  \\\n",
       "0           3            1               0   58.000000  51.739733         115   \n",
       "1           3            1               0    3.333333   3.214550           7   \n",
       "2           1            1               0   21.000000        NaN          21   \n",
       "3           2            1               0   32.500000   0.707107          33   \n",
       "4           5            1               0   11.200000  13.479614          30   \n",
       "\n",
       "   days_since_last_play  avg_session_gap  last_7day_activity  churned  \\\n",
       "0                     4         0.015833                   3     True   \n",
       "1                     4         0.008889                   3     True   \n",
       "2                     5         0.000000                   1     True   \n",
       "3                     4         0.014444                   2     True   \n",
       "4                     4         0.003264                   5     True   \n",
       "\n",
       "            device  \n",
       "0                0  \n",
       "1  000000000000000  \n",
       "2  010941525590041  \n",
       "3  012345678901237  \n",
       "4  012345678912345  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_churn_features(player_df, observation_days, prediction_days=7):\n",
    "    \"\"\"\n",
    "    Create features for a player based on their activity during the observation period\n",
    "    and determine if they churned during the prediction period.\n",
    "    \"\"\"\n",
    "    # Sort by datetime\n",
    "    player_df = player_df.sort_values('datetime')\n",
    "    \n",
    "    # Get the last datetime in the observation period\n",
    "    last_obs_time = player_df['datetime'].min() + timedelta(days=observation_days)\n",
    "    \n",
    "    # Split data into observation and prediction periods\n",
    "    obs_df = player_df[player_df['datetime'] <= last_obs_time]\n",
    "    pred_df = player_df[player_df['datetime'] > last_obs_time]\n",
    "    \n",
    "    # Calculate features from observation period\n",
    "    features = {\n",
    "        'play_count': len(obs_df),\n",
    "        'active_days': obs_df['datetime'].dt.date.nunique(),\n",
    "        'total_playtime': obs_df['duration'].sum() if 'duration' in obs_df.columns else 0,\n",
    "        'mean_score': obs_df['score'].mean(),\n",
    "        'score_std': obs_df['score'].std(),\n",
    "        'best_score': obs_df['score'].max(),\n",
    "        'days_since_last_play': (last_obs_time - obs_df['datetime'].max()).days,\n",
    "        'avg_session_gap': obs_df['datetime'].diff().mean().total_seconds() / 3600 if len(obs_df) > 1 else 0,\n",
    "        'last_7day_activity': len(obs_df[obs_df['datetime'] >= last_obs_time - timedelta(days=7)])\n",
    "    }\n",
    "    \n",
    "    # Calculate churn label if prediction period is specified\n",
    "    if prediction_days > 0:\n",
    "        last_pred_time = last_obs_time + timedelta(days=prediction_days)\n",
    "        pred_activity = pred_df[pred_df['datetime'] <= last_pred_time]\n",
    "        features['churned'] = len(pred_activity) == 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Process training data (DS1)\n",
    "print(\"Creating features for DS1 (training set)...\")\n",
    "ds1_features = []\n",
    "\n",
    "for player_id, player_df in train_df.groupby('device'):\n",
    "    try:\n",
    "        features = create_churn_features(player_df, observation_days=5, prediction_days=7)\n",
    "        features['device'] = player_id\n",
    "        ds1_features.append(features)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing player {player_id}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "ds1 = pd.DataFrame(ds1_features)\n",
    "print(f\"\\nCreated {len(ds1)} training samples\")\n",
    "print(\"\\nSample features:\")\n",
    "display(ds1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating features for DS2 (test set)...\n",
      "\n",
      "Created 5192 test samples\n",
      "\n",
      "Sample features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>play_count</th>\n",
       "      <th>active_days</th>\n",
       "      <th>total_playtime</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>score_std</th>\n",
       "      <th>best_score</th>\n",
       "      <th>days_since_last_play</th>\n",
       "      <th>avg_session_gap</th>\n",
       "      <th>last_7day_activity</th>\n",
       "      <th>churned</th>\n",
       "      <th>device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>13.892444</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0.991296</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>014035001426733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>40.571429</td>\n",
       "      <td>43.964521</td>\n",
       "      <td>168</td>\n",
       "      <td>4</td>\n",
       "      <td>1.623120</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>014097000302455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>014097001014984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>153.923077</td>\n",
       "      <td>188.298726</td>\n",
       "      <td>507</td>\n",
       "      <td>4</td>\n",
       "      <td>1.743981</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>014097008062978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>108.166667</td>\n",
       "      <td>118.560392</td>\n",
       "      <td>335</td>\n",
       "      <td>4</td>\n",
       "      <td>0.026111</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>014097008353997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   play_count  active_days  total_playtime  mean_score   score_std  \\\n",
       "0           4            1               0   12.500000   13.892444   \n",
       "1          14            2               0   40.571429   43.964521   \n",
       "2           1            1               0   20.000000         NaN   \n",
       "3          13            2               0  153.923077  188.298726   \n",
       "4           6            1               0  108.166667  118.560392   \n",
       "\n",
       "   best_score  days_since_last_play  avg_session_gap  last_7day_activity  \\\n",
       "0          32                     4         0.991296                   4   \n",
       "1         168                     4         1.623120                  14   \n",
       "2          20                     5         0.000000                   1   \n",
       "3         507                     4         1.743981                  13   \n",
       "4         335                     4         0.026111                   6   \n",
       "\n",
       "   churned           device  \n",
       "0     True  014035001426733  \n",
       "1    False  014097000302455  \n",
       "2     True  014097001014984  \n",
       "3     True  014097008062978  \n",
       "4     True  014097008353997  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved datasets:\n",
      "- DS1 (Train): ../data/game1_processed/ds1_train.csv\n",
      "- DS2 (Test): ../data/game1_processed/ds2_test.csv\n"
     ]
    }
   ],
   "source": [
    "def process_test_data(test_df, observation_days=5):\n",
    "    \"\"\"\n",
    "    Process the test data (DS2) using the same feature extraction as DS1.\n",
    "    Note: We don't calculate churn labels for DS2 since it's for evaluation only.\n",
    "    \"\"\"\n",
    "    print(\"Creating features for DS2 (test set)...\")\n",
    "    ds2_features = []\n",
    "    \n",
    "    for player_id, player_df in test_df.groupby('device'):\n",
    "        try:\n",
    "            # Use same feature extraction but without prediction period\n",
    "            features = create_churn_features(player_df, observation_days, prediction_days=10)\n",
    "            \n",
    "            # Store player ID for reference\n",
    "            features['device'] = player_id  \n",
    "            ds2_features.append(features)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing player {player_id}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    ds2 = pd.DataFrame(ds2_features)\n",
    "    print(f\"\\nCreated {len(ds2)} test samples\")\n",
    "    print(\"\\nSample features:\")\n",
    "    display(ds2.head())\n",
    "    \n",
    "    return ds2\n",
    "\n",
    "# Process test data (DS2)\n",
    "ds2 = process_test_data(test_df)\n",
    "\n",
    "# Save the processed datasets\n",
    "ds1.to_csv(\"data/game1_processed/ds1_train.csv\", index=False)\n",
    "ds2.to_csv(\"data/game1_processed/ds2_test.csv\", index=False)\n",
    "print(\"\\nSaved datasets:\")\n",
    "print(\"- DS1 (Train): ../data/game1_processed/ds1_train.csv\")\n",
    "print(\"- DS2 (Test): ../data/game1_processed/ds2_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree...\n",
      "Training Random Forest...\n",
      "Training Logistic Regression...\n",
      "\n",
      "Decision Tree Feature Importance:\n",
      "days_since_last_play    0.581149\n",
      "active_days             0.160392\n",
      "avg_session_gap         0.114609\n",
      "last_7day_activity      0.056582\n",
      "play_count              0.056324\n",
      "score_std               0.021106\n",
      "best_score              0.007978\n",
      "mean_score              0.001859\n",
      "total_playtime          0.000000\n",
      "dtype: float64\n",
      "\n",
      "Random Forest Feature Importance:\n",
      "active_days             0.327116\n",
      "days_since_last_play    0.219592\n",
      "avg_session_gap         0.148230\n",
      "play_count              0.122257\n",
      "last_7day_activity      0.109172\n",
      "best_score              0.026220\n",
      "mean_score              0.023752\n",
      "score_std               0.023660\n",
      "total_playtime          0.000000\n",
      "dtype: float64\n",
      "\n",
      "Saved test predictions: ../data/game1_processed/ds2_with_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def prepare_model_data(ds1, ds2):\n",
    "    \"\"\"Prepare features and labels for modeling\"\"\"\n",
    "    # Features (exclude device ID and churn label)\n",
    "    feature_cols = [col for col in ds1.columns if col not in ['device', 'churned']]\n",
    "    \n",
    "    # DS1 (Train)\n",
    "    X_train = ds1[feature_cols]\n",
    "    y_train = ds1['churned']\n",
    "    \n",
    "    # DS2 (Test) \n",
    "    X_test = ds2[feature_cols]\n",
    "    \n",
    "    # Impute missing values (using train stats)\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_test = imputer.transform(X_test)\n",
    "    \n",
    "    # Scale features (using train stats)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, feature_cols\n",
    "\n",
    "def train_models(X_train, y_train):\n",
    "    \"\"\"Train multiple classifiers\"\"\"\n",
    "    models = {\n",
    "        'Decision Tree': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42)\n",
    "    }\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    return models\n",
    "\n",
    "def evaluate_models(models, X_test, ds2, feature_cols):\n",
    "    \"\"\"Evaluate models on test data\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        # Get predicted probabilities\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        ds2[f'{name}_churn_prob'] = y_proba\n",
    "        \n",
    "        # Feature importance (for tree models)\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importance = pd.Series(model.feature_importances_, index=feature_cols)\n",
    "            print(f\"\\n{name} Feature Importance:\")\n",
    "            print(importance.sort_values(ascending=False).head(10))\n",
    "        \n",
    "        results[name] = model\n",
    "    \n",
    "    # Save test results with predictions\n",
    "    ds2.to_csv(\"data/game1_processed/ds2_with_predictions.csv\", index=False)\n",
    "    print(\"\\nSaved test predictions: ../data/game1_processed/ds2_with_predictions.csv\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Prepare data\n",
    "X_train, X_test, y_train, feature_cols = prepare_model_data(ds1, ds2)\n",
    "\n",
    "# Train models\n",
    "models = train_models(X_train, y_train)\n",
    "\n",
    "# Evaluate on DS2\n",
    "model_results = evaluate_models(models, X_test, ds2, feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DS1 (training) as JSONL: ../data/game1_processed/ds1_train.jsonl\n",
      "Saved DS2 (test) as JSONL: ../data/game1_processed/ds2_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Save datasets in JSONL format (required by PDF)\n",
    "import jsonlines\n",
    "\n",
    "def save_to_jsonl(df, path):\n",
    "    \"\"\"Save DataFrame to JSONL file\"\"\"\n",
    "    with jsonlines.open(path, 'w') as writer:\n",
    "        writer.write_all(df.to_dict('records'))\n",
    "\n",
    "# Save DS1 (training data)\n",
    "save_to_jsonl(ds1, \"data/game1_processed/ds1_train.jsonl\")\n",
    "print(\"Saved DS1 (training) as JSONL: ../data/game1_processed/ds1_train.jsonl\")\n",
    "\n",
    "# Save DS2 (test data) - without churn labels if they don't exist\n",
    "if 'churned' in ds2.columns:\n",
    "    save_to_jsonl(ds2.drop(columns=['churned']), \"data/game1_processed/ds2_test.jsonl\")\n",
    "else:\n",
    "    save_to_jsonl(ds2, \"data/game1_processed/ds2_test.jsonl\")\n",
    "print(\"Saved DS2 (test) as JSONL: ../data/game1_processed/ds2_test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
